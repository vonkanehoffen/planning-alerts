# This file was generated based on ".graphqlconfig". Do not edit manually.

schema {
  query: query_root
  mutation: mutation_root
  subscription: subscription_root
}

"columns and relationships of \"council\""
type council {
  council_type: String!
  id: Int!
  "An array relationship"
  pa_scrapes(
    "distinct select on columns"
    distinct_on: [pa_scrape_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_scrape_order_by!],
    "filter the rows returned"
    where: pa_scrape_bool_exp
  ): [pa_scrape!]!
  "An aggregated array relationship"
  pa_scrapes_aggregate(
    "distinct select on columns"
    distinct_on: [pa_scrape_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_scrape_order_by!],
    "filter the rows returned"
    where: pa_scrape_bool_exp
  ): pa_scrape_aggregate!
  "An array relationship"
  pa_statuses(
    "distinct select on columns"
    distinct_on: [pa_status_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_status_order_by!],
    "filter the rows returned"
    where: pa_status_bool_exp
  ): [pa_status!]!
  "An aggregated array relationship"
  pa_statuses_aggregate(
    "distinct select on columns"
    distinct_on: [pa_status_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_status_order_by!],
    "filter the rows returned"
    where: pa_status_bool_exp
  ): pa_status_aggregate!
  portal_url: String
  "An array relationship"
  scrape_logs(
    "distinct select on columns"
    distinct_on: [scrape_log_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [scrape_log_order_by!],
    "filter the rows returned"
    where: scrape_log_bool_exp
  ): [scrape_log!]!
  "An aggregated array relationship"
  scrape_logs_aggregate(
    "distinct select on columns"
    distinct_on: [scrape_log_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [scrape_log_order_by!],
    "filter the rows returned"
    where: scrape_log_bool_exp
  ): scrape_log_aggregate!
  scraper: String
  title: String!
  "An array relationship"
  users(
    "distinct select on columns"
    distinct_on: [users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [users_order_by!],
    "filter the rows returned"
    where: users_bool_exp
  ): [users!]!
  "An aggregated array relationship"
  users_aggregate(
    "distinct select on columns"
    distinct_on: [users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [users_order_by!],
    "filter the rows returned"
    where: users_bool_exp
  ): users_aggregate!
}

"aggregated selection of \"council\""
type council_aggregate {
  aggregate: council_aggregate_fields
  nodes: [council!]!
}

"aggregate fields of \"council\""
type council_aggregate_fields {
  avg: council_avg_fields
  count(columns: [council_select_column!], distinct: Boolean): Int
  max: council_max_fields
  min: council_min_fields
  stddev: council_stddev_fields
  stddev_pop: council_stddev_pop_fields
  stddev_samp: council_stddev_samp_fields
  sum: council_sum_fields
  var_pop: council_var_pop_fields
  var_samp: council_var_samp_fields
  variance: council_variance_fields
}

"aggregate avg on columns"
type council_avg_fields {
  id: Float
}

"aggregate max on columns"
type council_max_fields {
  council_type: String
  id: Int
  portal_url: String
  scraper: String
  title: String
}

"aggregate min on columns"
type council_min_fields {
  council_type: String
  id: Int
  portal_url: String
  scraper: String
  title: String
}

"response of any mutation on the table \"council\""
type council_mutation_response {
  "number of affected rows by the mutation"
  affected_rows: Int!
  "data of the affected rows by the mutation"
  returning: [council!]!
}

"aggregate stddev on columns"
type council_stddev_fields {
  id: Float
}

"aggregate stddev_pop on columns"
type council_stddev_pop_fields {
  id: Float
}

"aggregate stddev_samp on columns"
type council_stddev_samp_fields {
  id: Float
}

"aggregate sum on columns"
type council_sum_fields {
  id: Int
}

"aggregate var_pop on columns"
type council_var_pop_fields {
  id: Float
}

"aggregate var_samp on columns"
type council_var_samp_fields {
  id: Float
}

"aggregate variance on columns"
type council_variance_fields {
  id: Float
}

"""

FCM device tokens for users


columns and relationships of "fcm_token"
"""
type fcm_token {
  created_at: timestamptz
  device_id: String!
  token: String!
  "An object relationship"
  user: users!
  user_id: String!
}

"aggregated selection of \"fcm_token\""
type fcm_token_aggregate {
  aggregate: fcm_token_aggregate_fields
  nodes: [fcm_token!]!
}

"aggregate fields of \"fcm_token\""
type fcm_token_aggregate_fields {
  count(columns: [fcm_token_select_column!], distinct: Boolean): Int
  max: fcm_token_max_fields
  min: fcm_token_min_fields
}

"aggregate max on columns"
type fcm_token_max_fields {
  created_at: timestamptz
  device_id: String
  token: String
  user_id: String
}

"aggregate min on columns"
type fcm_token_min_fields {
  created_at: timestamptz
  device_id: String
  token: String
  user_id: String
}

"response of any mutation on the table \"fcm_token\""
type fcm_token_mutation_response {
  "number of affected rows by the mutation"
  affected_rows: Int!
  "data of the affected rows by the mutation"
  returning: [fcm_token!]!
}

"mutation root"
type mutation_root {
  "delete data from the table: \"council\""
  delete_council(
    "filter the rows which have to be deleted"
    where: council_bool_exp!
  ): council_mutation_response
  "delete single row from the table: \"council\""
  delete_council_by_pk(id: Int!): council
  "delete data from the table: \"fcm_token\""
  delete_fcm_token(
    "filter the rows which have to be deleted"
    where: fcm_token_bool_exp!
  ): fcm_token_mutation_response
  "delete single row from the table: \"fcm_token\""
  delete_fcm_token_by_pk(device_id: String!): fcm_token
  "delete data from the table: \"pa_scrape\""
  delete_pa_scrape(
    "filter the rows which have to be deleted"
    where: pa_scrape_bool_exp!
  ): pa_scrape_mutation_response
  "delete single row from the table: \"pa_scrape\""
  delete_pa_scrape_by_pk(id: Int!): pa_scrape
  "delete data from the table: \"pa_status\""
  delete_pa_status(
    "filter the rows which have to be deleted"
    where: pa_status_bool_exp!
  ): pa_status_mutation_response
  "delete single row from the table: \"pa_status\""
  delete_pa_status_by_pk(id: String!): pa_status
  "delete data from the table: \"scrape_log\""
  delete_scrape_log(
    "filter the rows which have to be deleted"
    where: scrape_log_bool_exp!
  ): scrape_log_mutation_response
  "delete single row from the table: \"scrape_log\""
  delete_scrape_log_by_pk(id: Int!): scrape_log
  "delete data from the table: \"users\""
  delete_users(
    "filter the rows which have to be deleted"
    where: users_bool_exp!
  ): users_mutation_response
  "delete single row from the table: \"users\""
  delete_users_by_pk(id: String!): users
  "insert data into the table: \"council\""
  insert_council(
    "the rows to be inserted"
    objects: [council_insert_input!]!,
    "on conflict condition"
    on_conflict: council_on_conflict
  ): council_mutation_response
  "insert a single row into the table: \"council\""
  insert_council_one(
    "the row to be inserted"
    object: council_insert_input!,
    "on conflict condition"
    on_conflict: council_on_conflict
  ): council
  "insert data into the table: \"fcm_token\""
  insert_fcm_token(
    "the rows to be inserted"
    objects: [fcm_token_insert_input!]!,
    "on conflict condition"
    on_conflict: fcm_token_on_conflict
  ): fcm_token_mutation_response
  "insert a single row into the table: \"fcm_token\""
  insert_fcm_token_one(
    "the row to be inserted"
    object: fcm_token_insert_input!,
    "on conflict condition"
    on_conflict: fcm_token_on_conflict
  ): fcm_token
  "insert data into the table: \"pa_scrape\""
  insert_pa_scrape(
    "the rows to be inserted"
    objects: [pa_scrape_insert_input!]!,
    "on conflict condition"
    on_conflict: pa_scrape_on_conflict
  ): pa_scrape_mutation_response
  "insert a single row into the table: \"pa_scrape\""
  insert_pa_scrape_one(
    "the row to be inserted"
    object: pa_scrape_insert_input!,
    "on conflict condition"
    on_conflict: pa_scrape_on_conflict
  ): pa_scrape
  "insert data into the table: \"pa_status\""
  insert_pa_status(
    "the rows to be inserted"
    objects: [pa_status_insert_input!]!,
    "on conflict condition"
    on_conflict: pa_status_on_conflict
  ): pa_status_mutation_response
  "insert a single row into the table: \"pa_status\""
  insert_pa_status_one(
    "the row to be inserted"
    object: pa_status_insert_input!,
    "on conflict condition"
    on_conflict: pa_status_on_conflict
  ): pa_status
  "insert data into the table: \"scrape_log\""
  insert_scrape_log(
    "the rows to be inserted"
    objects: [scrape_log_insert_input!]!,
    "on conflict condition"
    on_conflict: scrape_log_on_conflict
  ): scrape_log_mutation_response
  "insert a single row into the table: \"scrape_log\""
  insert_scrape_log_one(
    "the row to be inserted"
    object: scrape_log_insert_input!,
    "on conflict condition"
    on_conflict: scrape_log_on_conflict
  ): scrape_log
  "insert data into the table: \"users\""
  insert_users(
    "the rows to be inserted"
    objects: [users_insert_input!]!,
    "on conflict condition"
    on_conflict: users_on_conflict
  ): users_mutation_response
  "insert a single row into the table: \"users\""
  insert_users_one(
    "the row to be inserted"
    object: users_insert_input!,
    "on conflict condition"
    on_conflict: users_on_conflict
  ): users
  "update data of the table: \"council\""
  update_council(
    "increments the integer columns with given value of the filtered values"
    _inc: council_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: council_set_input,
    "filter the rows which have to be updated"
    where: council_bool_exp!
  ): council_mutation_response
  "update single row of the table: \"council\""
  update_council_by_pk(
    "increments the integer columns with given value of the filtered values"
    _inc: council_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: council_set_input,
    pk_columns: council_pk_columns_input!
  ): council
  "update data of the table: \"fcm_token\""
  update_fcm_token(
    "sets the columns of the filtered rows to the given values"
    _set: fcm_token_set_input,
    "filter the rows which have to be updated"
    where: fcm_token_bool_exp!
  ): fcm_token_mutation_response
  "update single row of the table: \"fcm_token\""
  update_fcm_token_by_pk(
    "sets the columns of the filtered rows to the given values"
    _set: fcm_token_set_input,
    pk_columns: fcm_token_pk_columns_input!
  ): fcm_token
  "update data of the table: \"pa_scrape\""
  update_pa_scrape(
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: pa_scrape_append_input,
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: pa_scrape_delete_at_path_input,
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: pa_scrape_delete_elem_input,
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: pa_scrape_delete_key_input,
    "increments the integer columns with given value of the filtered values"
    _inc: pa_scrape_inc_input,
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: pa_scrape_prepend_input,
    "sets the columns of the filtered rows to the given values"
    _set: pa_scrape_set_input,
    "filter the rows which have to be updated"
    where: pa_scrape_bool_exp!
  ): pa_scrape_mutation_response
  "update single row of the table: \"pa_scrape\""
  update_pa_scrape_by_pk(
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: pa_scrape_append_input,
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: pa_scrape_delete_at_path_input,
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: pa_scrape_delete_elem_input,
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: pa_scrape_delete_key_input,
    "increments the integer columns with given value of the filtered values"
    _inc: pa_scrape_inc_input,
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: pa_scrape_prepend_input,
    "sets the columns of the filtered rows to the given values"
    _set: pa_scrape_set_input,
    pk_columns: pa_scrape_pk_columns_input!
  ): pa_scrape
  "update data of the table: \"pa_status\""
  update_pa_status(
    "increments the integer columns with given value of the filtered values"
    _inc: pa_status_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: pa_status_set_input,
    "filter the rows which have to be updated"
    where: pa_status_bool_exp!
  ): pa_status_mutation_response
  "update single row of the table: \"pa_status\""
  update_pa_status_by_pk(
    "increments the integer columns with given value of the filtered values"
    _inc: pa_status_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: pa_status_set_input,
    pk_columns: pa_status_pk_columns_input!
  ): pa_status
  "update data of the table: \"scrape_log\""
  update_scrape_log(
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: scrape_log_append_input,
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: scrape_log_delete_at_path_input,
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: scrape_log_delete_elem_input,
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: scrape_log_delete_key_input,
    "increments the integer columns with given value of the filtered values"
    _inc: scrape_log_inc_input,
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: scrape_log_prepend_input,
    "sets the columns of the filtered rows to the given values"
    _set: scrape_log_set_input,
    "filter the rows which have to be updated"
    where: scrape_log_bool_exp!
  ): scrape_log_mutation_response
  "update single row of the table: \"scrape_log\""
  update_scrape_log_by_pk(
    "append existing jsonb value of filtered columns with new jsonb value"
    _append: scrape_log_append_input,
    "delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
    _delete_at_path: scrape_log_delete_at_path_input,
    "delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
    _delete_elem: scrape_log_delete_elem_input,
    "delete key/value pair or string element. key/value pairs are matched based on their key value"
    _delete_key: scrape_log_delete_key_input,
    "increments the integer columns with given value of the filtered values"
    _inc: scrape_log_inc_input,
    "prepend existing jsonb value of filtered columns with new jsonb value"
    _prepend: scrape_log_prepend_input,
    "sets the columns of the filtered rows to the given values"
    _set: scrape_log_set_input,
    pk_columns: scrape_log_pk_columns_input!
  ): scrape_log
  "update data of the table: \"users\""
  update_users(
    "increments the integer columns with given value of the filtered values"
    _inc: users_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: users_set_input,
    "filter the rows which have to be updated"
    where: users_bool_exp!
  ): users_mutation_response
  "update single row of the table: \"users\""
  update_users_by_pk(
    "increments the integer columns with given value of the filtered values"
    _inc: users_inc_input,
    "sets the columns of the filtered rows to the given values"
    _set: users_set_input,
    pk_columns: users_pk_columns_input!
  ): users
}

"columns and relationships of \"pa_scrape\""
type pa_scrape {
  contacts(
    "JSON select path"
    path: String
  ): jsonb
  "An object relationship"
  council: council
  council_id: Int
  further_information(
    "JSON select path"
    path: String
  ): jsonb
  id: Int!
  important_dates(
    "JSON select path"
    path: String
  ): jsonb
  list_type: String!
  "An object relationship"
  pa_status: pa_status!
  reference: String!
  scraped_at: timestamptz!
  scraper: String!
  summary(
    "JSON select path"
    path: String
  ): jsonb
  url: String!
}

"aggregated selection of \"pa_scrape\""
type pa_scrape_aggregate {
  aggregate: pa_scrape_aggregate_fields
  nodes: [pa_scrape!]!
}

"aggregate fields of \"pa_scrape\""
type pa_scrape_aggregate_fields {
  avg: pa_scrape_avg_fields
  count(columns: [pa_scrape_select_column!], distinct: Boolean): Int
  max: pa_scrape_max_fields
  min: pa_scrape_min_fields
  stddev: pa_scrape_stddev_fields
  stddev_pop: pa_scrape_stddev_pop_fields
  stddev_samp: pa_scrape_stddev_samp_fields
  sum: pa_scrape_sum_fields
  var_pop: pa_scrape_var_pop_fields
  var_samp: pa_scrape_var_samp_fields
  variance: pa_scrape_variance_fields
}

"aggregate avg on columns"
type pa_scrape_avg_fields {
  council_id: Float
  id: Float
}

"aggregate max on columns"
type pa_scrape_max_fields {
  council_id: Int
  id: Int
  list_type: String
  reference: String
  scraped_at: timestamptz
  scraper: String
  url: String
}

"aggregate min on columns"
type pa_scrape_min_fields {
  council_id: Int
  id: Int
  list_type: String
  reference: String
  scraped_at: timestamptz
  scraper: String
  url: String
}

"response of any mutation on the table \"pa_scrape\""
type pa_scrape_mutation_response {
  "number of affected rows by the mutation"
  affected_rows: Int!
  "data of the affected rows by the mutation"
  returning: [pa_scrape!]!
}

"aggregate stddev on columns"
type pa_scrape_stddev_fields {
  council_id: Float
  id: Float
}

"aggregate stddev_pop on columns"
type pa_scrape_stddev_pop_fields {
  council_id: Float
  id: Float
}

"aggregate stddev_samp on columns"
type pa_scrape_stddev_samp_fields {
  council_id: Float
  id: Float
}

"aggregate sum on columns"
type pa_scrape_sum_fields {
  council_id: Int
  id: Int
}

"aggregate var_pop on columns"
type pa_scrape_var_pop_fields {
  council_id: Float
  id: Float
}

"aggregate var_samp on columns"
type pa_scrape_var_samp_fields {
  council_id: Float
  id: Float
}

"aggregate variance on columns"
type pa_scrape_variance_fields {
  council_id: Float
  id: Float
}

"columns and relationships of \"pa_status\""
type pa_status {
  address: String!
  application_validated: timestamptz
  "An object relationship"
  council: council
  council_id: Int
  "depreciated"
  council_name: String
  created_at: timestamptz!
  decision: String
  decision_issued_date: timestamptz
  id: String!
  location: geography
  open: Boolean!
  "An array relationship"
  pa_scrapes(
    "distinct select on columns"
    distinct_on: [pa_scrape_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_scrape_order_by!],
    "filter the rows returned"
    where: pa_scrape_bool_exp
  ): [pa_scrape!]!
  "An aggregated array relationship"
  pa_scrapes_aggregate(
    "distinct select on columns"
    distinct_on: [pa_scrape_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_scrape_order_by!],
    "filter the rows returned"
    where: pa_scrape_bool_exp
  ): pa_scrape_aggregate!
  proposal: String!
  status: String
  updated_at: timestamptz!
  url: String!
}

"aggregated selection of \"pa_status\""
type pa_status_aggregate {
  aggregate: pa_status_aggregate_fields
  nodes: [pa_status!]!
}

"aggregate fields of \"pa_status\""
type pa_status_aggregate_fields {
  avg: pa_status_avg_fields
  count(columns: [pa_status_select_column!], distinct: Boolean): Int
  max: pa_status_max_fields
  min: pa_status_min_fields
  stddev: pa_status_stddev_fields
  stddev_pop: pa_status_stddev_pop_fields
  stddev_samp: pa_status_stddev_samp_fields
  sum: pa_status_sum_fields
  var_pop: pa_status_var_pop_fields
  var_samp: pa_status_var_samp_fields
  variance: pa_status_variance_fields
}

"aggregate avg on columns"
type pa_status_avg_fields {
  council_id: Float
}

"aggregate max on columns"
type pa_status_max_fields {
  address: String
  application_validated: timestamptz
  council_id: Int
  council_name: String
  created_at: timestamptz
  decision: String
  decision_issued_date: timestamptz
  id: String
  proposal: String
  status: String
  updated_at: timestamptz
  url: String
}

"aggregate min on columns"
type pa_status_min_fields {
  address: String
  application_validated: timestamptz
  council_id: Int
  council_name: String
  created_at: timestamptz
  decision: String
  decision_issued_date: timestamptz
  id: String
  proposal: String
  status: String
  updated_at: timestamptz
  url: String
}

"response of any mutation on the table \"pa_status\""
type pa_status_mutation_response {
  "number of affected rows by the mutation"
  affected_rows: Int!
  "data of the affected rows by the mutation"
  returning: [pa_status!]!
}

"aggregate stddev on columns"
type pa_status_stddev_fields {
  council_id: Float
}

"aggregate stddev_pop on columns"
type pa_status_stddev_pop_fields {
  council_id: Float
}

"aggregate stddev_samp on columns"
type pa_status_stddev_samp_fields {
  council_id: Float
}

"aggregate sum on columns"
type pa_status_sum_fields {
  council_id: Int
}

"aggregate var_pop on columns"
type pa_status_var_pop_fields {
  council_id: Float
}

"aggregate var_samp on columns"
type pa_status_var_samp_fields {
  council_id: Float
}

"aggregate variance on columns"
type pa_status_variance_fields {
  council_id: Float
}

"query root"
type query_root {
  "fetch data from the table: \"council\""
  council(
    "distinct select on columns"
    distinct_on: [council_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [council_order_by!],
    "filter the rows returned"
    where: council_bool_exp
  ): [council!]!
  "fetch aggregated fields from the table: \"council\""
  council_aggregate(
    "distinct select on columns"
    distinct_on: [council_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [council_order_by!],
    "filter the rows returned"
    where: council_bool_exp
  ): council_aggregate!
  "fetch data from the table: \"council\" using primary key columns"
  council_by_pk(id: Int!): council
  "fetch data from the table: \"fcm_token\""
  fcm_token(
    "distinct select on columns"
    distinct_on: [fcm_token_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [fcm_token_order_by!],
    "filter the rows returned"
    where: fcm_token_bool_exp
  ): [fcm_token!]!
  "fetch aggregated fields from the table: \"fcm_token\""
  fcm_token_aggregate(
    "distinct select on columns"
    distinct_on: [fcm_token_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [fcm_token_order_by!],
    "filter the rows returned"
    where: fcm_token_bool_exp
  ): fcm_token_aggregate!
  "fetch data from the table: \"fcm_token\" using primary key columns"
  fcm_token_by_pk(device_id: String!): fcm_token
  "fetch data from the table: \"pa_scrape\""
  pa_scrape(
    "distinct select on columns"
    distinct_on: [pa_scrape_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_scrape_order_by!],
    "filter the rows returned"
    where: pa_scrape_bool_exp
  ): [pa_scrape!]!
  "fetch aggregated fields from the table: \"pa_scrape\""
  pa_scrape_aggregate(
    "distinct select on columns"
    distinct_on: [pa_scrape_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_scrape_order_by!],
    "filter the rows returned"
    where: pa_scrape_bool_exp
  ): pa_scrape_aggregate!
  "fetch data from the table: \"pa_scrape\" using primary key columns"
  pa_scrape_by_pk(id: Int!): pa_scrape
  "fetch data from the table: \"pa_status\""
  pa_status(
    "distinct select on columns"
    distinct_on: [pa_status_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_status_order_by!],
    "filter the rows returned"
    where: pa_status_bool_exp
  ): [pa_status!]!
  "fetch aggregated fields from the table: \"pa_status\""
  pa_status_aggregate(
    "distinct select on columns"
    distinct_on: [pa_status_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_status_order_by!],
    "filter the rows returned"
    where: pa_status_bool_exp
  ): pa_status_aggregate!
  "fetch data from the table: \"pa_status\" using primary key columns"
  pa_status_by_pk(id: String!): pa_status
  "fetch data from the table: \"scrape_log\""
  scrape_log(
    "distinct select on columns"
    distinct_on: [scrape_log_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [scrape_log_order_by!],
    "filter the rows returned"
    where: scrape_log_bool_exp
  ): [scrape_log!]!
  "fetch aggregated fields from the table: \"scrape_log\""
  scrape_log_aggregate(
    "distinct select on columns"
    distinct_on: [scrape_log_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [scrape_log_order_by!],
    "filter the rows returned"
    where: scrape_log_bool_exp
  ): scrape_log_aggregate!
  "fetch data from the table: \"scrape_log\" using primary key columns"
  scrape_log_by_pk(id: Int!): scrape_log
  "fetch data from the table: \"users\""
  users(
    "distinct select on columns"
    distinct_on: [users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [users_order_by!],
    "filter the rows returned"
    where: users_bool_exp
  ): [users!]!
  "fetch aggregated fields from the table: \"users\""
  users_aggregate(
    "distinct select on columns"
    distinct_on: [users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [users_order_by!],
    "filter the rows returned"
    where: users_bool_exp
  ): users_aggregate!
  "fetch data from the table: \"users\" using primary key columns"
  users_by_pk(id: String!): users
}

"columns and relationships of \"scrape_log\""
type scrape_log {
  "An object relationship"
  council: council
  council_id: Int
  event: String!
  id: Int!
  meta(
    "JSON select path"
    path: String
  ): jsonb!
  scraper: String!
  ts: timestamptz
}

"aggregated selection of \"scrape_log\""
type scrape_log_aggregate {
  aggregate: scrape_log_aggregate_fields
  nodes: [scrape_log!]!
}

"aggregate fields of \"scrape_log\""
type scrape_log_aggregate_fields {
  avg: scrape_log_avg_fields
  count(columns: [scrape_log_select_column!], distinct: Boolean): Int
  max: scrape_log_max_fields
  min: scrape_log_min_fields
  stddev: scrape_log_stddev_fields
  stddev_pop: scrape_log_stddev_pop_fields
  stddev_samp: scrape_log_stddev_samp_fields
  sum: scrape_log_sum_fields
  var_pop: scrape_log_var_pop_fields
  var_samp: scrape_log_var_samp_fields
  variance: scrape_log_variance_fields
}

"aggregate avg on columns"
type scrape_log_avg_fields {
  council_id: Float
  id: Float
}

"aggregate max on columns"
type scrape_log_max_fields {
  council_id: Int
  event: String
  id: Int
  scraper: String
  ts: timestamptz
}

"aggregate min on columns"
type scrape_log_min_fields {
  council_id: Int
  event: String
  id: Int
  scraper: String
  ts: timestamptz
}

"response of any mutation on the table \"scrape_log\""
type scrape_log_mutation_response {
  "number of affected rows by the mutation"
  affected_rows: Int!
  "data of the affected rows by the mutation"
  returning: [scrape_log!]!
}

"aggregate stddev on columns"
type scrape_log_stddev_fields {
  council_id: Float
  id: Float
}

"aggregate stddev_pop on columns"
type scrape_log_stddev_pop_fields {
  council_id: Float
  id: Float
}

"aggregate stddev_samp on columns"
type scrape_log_stddev_samp_fields {
  council_id: Float
  id: Float
}

"aggregate sum on columns"
type scrape_log_sum_fields {
  council_id: Int
  id: Int
}

"aggregate var_pop on columns"
type scrape_log_var_pop_fields {
  council_id: Float
  id: Float
}

"aggregate var_samp on columns"
type scrape_log_var_samp_fields {
  council_id: Float
  id: Float
}

"aggregate variance on columns"
type scrape_log_variance_fields {
  council_id: Float
  id: Float
}

"subscription root"
type subscription_root {
  "fetch data from the table: \"council\""
  council(
    "distinct select on columns"
    distinct_on: [council_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [council_order_by!],
    "filter the rows returned"
    where: council_bool_exp
  ): [council!]!
  "fetch aggregated fields from the table: \"council\""
  council_aggregate(
    "distinct select on columns"
    distinct_on: [council_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [council_order_by!],
    "filter the rows returned"
    where: council_bool_exp
  ): council_aggregate!
  "fetch data from the table: \"council\" using primary key columns"
  council_by_pk(id: Int!): council
  "fetch data from the table: \"fcm_token\""
  fcm_token(
    "distinct select on columns"
    distinct_on: [fcm_token_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [fcm_token_order_by!],
    "filter the rows returned"
    where: fcm_token_bool_exp
  ): [fcm_token!]!
  "fetch aggregated fields from the table: \"fcm_token\""
  fcm_token_aggregate(
    "distinct select on columns"
    distinct_on: [fcm_token_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [fcm_token_order_by!],
    "filter the rows returned"
    where: fcm_token_bool_exp
  ): fcm_token_aggregate!
  "fetch data from the table: \"fcm_token\" using primary key columns"
  fcm_token_by_pk(device_id: String!): fcm_token
  "fetch data from the table: \"pa_scrape\""
  pa_scrape(
    "distinct select on columns"
    distinct_on: [pa_scrape_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_scrape_order_by!],
    "filter the rows returned"
    where: pa_scrape_bool_exp
  ): [pa_scrape!]!
  "fetch aggregated fields from the table: \"pa_scrape\""
  pa_scrape_aggregate(
    "distinct select on columns"
    distinct_on: [pa_scrape_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_scrape_order_by!],
    "filter the rows returned"
    where: pa_scrape_bool_exp
  ): pa_scrape_aggregate!
  "fetch data from the table: \"pa_scrape\" using primary key columns"
  pa_scrape_by_pk(id: Int!): pa_scrape
  "fetch data from the table: \"pa_status\""
  pa_status(
    "distinct select on columns"
    distinct_on: [pa_status_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_status_order_by!],
    "filter the rows returned"
    where: pa_status_bool_exp
  ): [pa_status!]!
  "fetch aggregated fields from the table: \"pa_status\""
  pa_status_aggregate(
    "distinct select on columns"
    distinct_on: [pa_status_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [pa_status_order_by!],
    "filter the rows returned"
    where: pa_status_bool_exp
  ): pa_status_aggregate!
  "fetch data from the table: \"pa_status\" using primary key columns"
  pa_status_by_pk(id: String!): pa_status
  "fetch data from the table: \"scrape_log\""
  scrape_log(
    "distinct select on columns"
    distinct_on: [scrape_log_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [scrape_log_order_by!],
    "filter the rows returned"
    where: scrape_log_bool_exp
  ): [scrape_log!]!
  "fetch aggregated fields from the table: \"scrape_log\""
  scrape_log_aggregate(
    "distinct select on columns"
    distinct_on: [scrape_log_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [scrape_log_order_by!],
    "filter the rows returned"
    where: scrape_log_bool_exp
  ): scrape_log_aggregate!
  "fetch data from the table: \"scrape_log\" using primary key columns"
  scrape_log_by_pk(id: Int!): scrape_log
  "fetch data from the table: \"users\""
  users(
    "distinct select on columns"
    distinct_on: [users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [users_order_by!],
    "filter the rows returned"
    where: users_bool_exp
  ): [users!]!
  "fetch aggregated fields from the table: \"users\""
  users_aggregate(
    "distinct select on columns"
    distinct_on: [users_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [users_order_by!],
    "filter the rows returned"
    where: users_bool_exp
  ): users_aggregate!
  "fetch data from the table: \"users\" using primary key columns"
  users_by_pk(id: String!): users
}

"columns and relationships of \"users\""
type users {
  "An object relationship"
  council: council
  council_id: Int
  created_at: timestamptz
  email: String
  "An array relationship"
  fcm_tokens(
    "distinct select on columns"
    distinct_on: [fcm_token_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [fcm_token_order_by!],
    "filter the rows returned"
    where: fcm_token_bool_exp
  ): [fcm_token!]!
  "An aggregated array relationship"
  fcm_tokens_aggregate(
    "distinct select on columns"
    distinct_on: [fcm_token_select_column!],
    "limit the number of rows returned"
    limit: Int,
    "skip the first n rows. Use only with order_by"
    offset: Int,
    "sort the rows by one or more columns"
    order_by: [fcm_token_order_by!],
    "filter the rows returned"
    where: fcm_token_bool_exp
  ): fcm_token_aggregate!
  id: String!
  location: geography
  name: String
}

"aggregated selection of \"users\""
type users_aggregate {
  aggregate: users_aggregate_fields
  nodes: [users!]!
}

"aggregate fields of \"users\""
type users_aggregate_fields {
  avg: users_avg_fields
  count(columns: [users_select_column!], distinct: Boolean): Int
  max: users_max_fields
  min: users_min_fields
  stddev: users_stddev_fields
  stddev_pop: users_stddev_pop_fields
  stddev_samp: users_stddev_samp_fields
  sum: users_sum_fields
  var_pop: users_var_pop_fields
  var_samp: users_var_samp_fields
  variance: users_variance_fields
}

"aggregate avg on columns"
type users_avg_fields {
  council_id: Float
}

"aggregate max on columns"
type users_max_fields {
  council_id: Int
  created_at: timestamptz
  email: String
  id: String
  name: String
}

"aggregate min on columns"
type users_min_fields {
  council_id: Int
  created_at: timestamptz
  email: String
  id: String
  name: String
}

"response of any mutation on the table \"users\""
type users_mutation_response {
  "number of affected rows by the mutation"
  affected_rows: Int!
  "data of the affected rows by the mutation"
  returning: [users!]!
}

"aggregate stddev on columns"
type users_stddev_fields {
  council_id: Float
}

"aggregate stddev_pop on columns"
type users_stddev_pop_fields {
  council_id: Float
}

"aggregate stddev_samp on columns"
type users_stddev_samp_fields {
  council_id: Float
}

"aggregate sum on columns"
type users_sum_fields {
  council_id: Int
}

"aggregate var_pop on columns"
type users_var_pop_fields {
  council_id: Float
}

"aggregate var_samp on columns"
type users_var_samp_fields {
  council_id: Float
}

"aggregate variance on columns"
type users_variance_fields {
  council_id: Float
}

"unique or primary key constraints on table \"council\""
enum council_constraint {
  "unique or primary key constraint"
  council_pkey
  "unique or primary key constraint"
  council_portal_url_key
  "unique or primary key constraint"
  council_title_key
}

"select columns of table \"council\""
enum council_select_column {
  "column name"
  council_type
  "column name"
  id
  "column name"
  portal_url
  "column name"
  scraper
  "column name"
  title
}

"update columns of table \"council\""
enum council_update_column {
  "column name"
  council_type
  "column name"
  id
  "column name"
  portal_url
  "column name"
  scraper
  "column name"
  title
}

"unique or primary key constraints on table \"fcm_token\""
enum fcm_token_constraint {
  "unique or primary key constraint"
  fcm_token_device_id_key
  "unique or primary key constraint"
  fcm_token_pkey
}

"select columns of table \"fcm_token\""
enum fcm_token_select_column {
  "column name"
  created_at
  "column name"
  device_id
  "column name"
  token
  "column name"
  user_id
}

"update columns of table \"fcm_token\""
enum fcm_token_update_column {
  "column name"
  created_at
  "column name"
  device_id
  "column name"
  token
  "column name"
  user_id
}

"column ordering options"
enum order_by {
  "in the ascending order, nulls last"
  asc
  "in the ascending order, nulls first"
  asc_nulls_first
  "in the ascending order, nulls last"
  asc_nulls_last
  "in the descending order, nulls first"
  desc
  "in the descending order, nulls first"
  desc_nulls_first
  "in the descending order, nulls last"
  desc_nulls_last
}

"unique or primary key constraints on table \"pa_scrape\""
enum pa_scrape_constraint {
  "unique or primary key constraint"
  pa_scrape_decided_pkey
}

"select columns of table \"pa_scrape\""
enum pa_scrape_select_column {
  "column name"
  contacts
  "column name"
  council_id
  "column name"
  further_information
  "column name"
  id
  "column name"
  important_dates
  "column name"
  list_type
  "column name"
  reference
  "column name"
  scraped_at
  "column name"
  scraper
  "column name"
  summary
  "column name"
  url
}

"update columns of table \"pa_scrape\""
enum pa_scrape_update_column {
  "column name"
  contacts
  "column name"
  council_id
  "column name"
  further_information
  "column name"
  id
  "column name"
  important_dates
  "column name"
  list_type
  "column name"
  reference
  "column name"
  scraped_at
  "column name"
  scraper
  "column name"
  summary
  "column name"
  url
}

"unique or primary key constraints on table \"pa_status\""
enum pa_status_constraint {
  "unique or primary key constraint"
  pa_status_pkey
}

"select columns of table \"pa_status\""
enum pa_status_select_column {
  "column name"
  address
  "column name"
  application_validated
  "column name"
  council_id
  "column name"
  council_name
  "column name"
  created_at
  "column name"
  decision
  "column name"
  decision_issued_date
  "column name"
  id
  "column name"
  location
  "column name"
  open
  "column name"
  proposal
  "column name"
  status
  "column name"
  updated_at
  "column name"
  url
}

"update columns of table \"pa_status\""
enum pa_status_update_column {
  "column name"
  address
  "column name"
  application_validated
  "column name"
  council_id
  "column name"
  council_name
  "column name"
  created_at
  "column name"
  decision
  "column name"
  decision_issued_date
  "column name"
  id
  "column name"
  location
  "column name"
  open
  "column name"
  proposal
  "column name"
  status
  "column name"
  updated_at
  "column name"
  url
}

"unique or primary key constraints on table \"scrape_log\""
enum scrape_log_constraint {
  "unique or primary key constraint"
  scrape_log_pkey
}

"select columns of table \"scrape_log\""
enum scrape_log_select_column {
  "column name"
  council_id
  "column name"
  event
  "column name"
  id
  "column name"
  meta
  "column name"
  scraper
  "column name"
  ts
}

"update columns of table \"scrape_log\""
enum scrape_log_update_column {
  "column name"
  council_id
  "column name"
  event
  "column name"
  id
  "column name"
  meta
  "column name"
  scraper
  "column name"
  ts
}

"unique or primary key constraints on table \"users\""
enum users_constraint {
  "unique or primary key constraint"
  users_pkey
}

"select columns of table \"users\""
enum users_select_column {
  "column name"
  council_id
  "column name"
  created_at
  "column name"
  email
  "column name"
  id
  "column name"
  location
  "column name"
  name
}

"update columns of table \"users\""
enum users_update_column {
  "column name"
  council_id
  "column name"
  created_at
  "column name"
  email
  "column name"
  id
  "column name"
  location
  "column name"
  name
}

"expression to compare columns of type Boolean. All fields are combined with logical 'AND'."
input Boolean_comparison_exp {
  _eq: Boolean
  _gt: Boolean
  _gte: Boolean
  _in: [Boolean!]
  _is_null: Boolean
  _lt: Boolean
  _lte: Boolean
  _neq: Boolean
  _nin: [Boolean!]
}

"expression to compare columns of type Int. All fields are combined with logical 'AND'."
input Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

"expression to compare columns of type String. All fields are combined with logical 'AND'."
input String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String
  _ilike: String
  _in: [String!]
  _is_null: Boolean
  _like: String
  _lt: String
  _lte: String
  _neq: String
  _nilike: String
  _nin: [String!]
  _nlike: String
  _nsimilar: String
  _similar: String
}

"order by aggregate values of table \"council\""
input council_aggregate_order_by {
  avg: council_avg_order_by
  count: order_by
  max: council_max_order_by
  min: council_min_order_by
  stddev: council_stddev_order_by
  stddev_pop: council_stddev_pop_order_by
  stddev_samp: council_stddev_samp_order_by
  sum: council_sum_order_by
  var_pop: council_var_pop_order_by
  var_samp: council_var_samp_order_by
  variance: council_variance_order_by
}

"input type for inserting array relation for remote table \"council\""
input council_arr_rel_insert_input {
  data: [council_insert_input!]!
  on_conflict: council_on_conflict
}

"order by avg() on columns of table \"council\""
input council_avg_order_by {
  id: order_by
}

"Boolean expression to filter rows from the table \"council\". All fields are combined with a logical 'AND'."
input council_bool_exp {
  _and: [council_bool_exp]
  _not: council_bool_exp
  _or: [council_bool_exp]
  council_type: String_comparison_exp
  id: Int_comparison_exp
  pa_scrapes: pa_scrape_bool_exp
  pa_statuses: pa_status_bool_exp
  portal_url: String_comparison_exp
  scrape_logs: scrape_log_bool_exp
  scraper: String_comparison_exp
  title: String_comparison_exp
  users: users_bool_exp
}

"input type for incrementing integer column in table \"council\""
input council_inc_input {
  id: Int
}

"input type for inserting data into table \"council\""
input council_insert_input {
  council_type: String
  id: Int
  pa_scrapes: pa_scrape_arr_rel_insert_input
  pa_statuses: pa_status_arr_rel_insert_input
  portal_url: String
  scrape_logs: scrape_log_arr_rel_insert_input
  scraper: String
  title: String
  users: users_arr_rel_insert_input
}

"order by max() on columns of table \"council\""
input council_max_order_by {
  council_type: order_by
  id: order_by
  portal_url: order_by
  scraper: order_by
  title: order_by
}

"order by min() on columns of table \"council\""
input council_min_order_by {
  council_type: order_by
  id: order_by
  portal_url: order_by
  scraper: order_by
  title: order_by
}

"input type for inserting object relation for remote table \"council\""
input council_obj_rel_insert_input {
  data: council_insert_input!
  on_conflict: council_on_conflict
}

"on conflict condition type for table \"council\""
input council_on_conflict {
  constraint: council_constraint!
  update_columns: [council_update_column!]!
  where: council_bool_exp
}

"ordering options when selecting data from \"council\""
input council_order_by {
  council_type: order_by
  id: order_by
  pa_scrapes_aggregate: pa_scrape_aggregate_order_by
  pa_statuses_aggregate: pa_status_aggregate_order_by
  portal_url: order_by
  scrape_logs_aggregate: scrape_log_aggregate_order_by
  scraper: order_by
  title: order_by
  users_aggregate: users_aggregate_order_by
}

"primary key columns input for table: \"council\""
input council_pk_columns_input {
  id: Int!
}

"input type for updating data in table \"council\""
input council_set_input {
  council_type: String
  id: Int
  portal_url: String
  scraper: String
  title: String
}

"order by stddev() on columns of table \"council\""
input council_stddev_order_by {
  id: order_by
}

"order by stddev_pop() on columns of table \"council\""
input council_stddev_pop_order_by {
  id: order_by
}

"order by stddev_samp() on columns of table \"council\""
input council_stddev_samp_order_by {
  id: order_by
}

"order by sum() on columns of table \"council\""
input council_sum_order_by {
  id: order_by
}

"order by var_pop() on columns of table \"council\""
input council_var_pop_order_by {
  id: order_by
}

"order by var_samp() on columns of table \"council\""
input council_var_samp_order_by {
  id: order_by
}

"order by variance() on columns of table \"council\""
input council_variance_order_by {
  id: order_by
}

"order by aggregate values of table \"fcm_token\""
input fcm_token_aggregate_order_by {
  count: order_by
  max: fcm_token_max_order_by
  min: fcm_token_min_order_by
}

"input type for inserting array relation for remote table \"fcm_token\""
input fcm_token_arr_rel_insert_input {
  data: [fcm_token_insert_input!]!
  on_conflict: fcm_token_on_conflict
}

"Boolean expression to filter rows from the table \"fcm_token\". All fields are combined with a logical 'AND'."
input fcm_token_bool_exp {
  _and: [fcm_token_bool_exp]
  _not: fcm_token_bool_exp
  _or: [fcm_token_bool_exp]
  created_at: timestamptz_comparison_exp
  device_id: String_comparison_exp
  token: String_comparison_exp
  user: users_bool_exp
  user_id: String_comparison_exp
}

"input type for inserting data into table \"fcm_token\""
input fcm_token_insert_input {
  created_at: timestamptz
  device_id: String
  token: String
  user: users_obj_rel_insert_input
  user_id: String
}

"order by max() on columns of table \"fcm_token\""
input fcm_token_max_order_by {
  created_at: order_by
  device_id: order_by
  token: order_by
  user_id: order_by
}

"order by min() on columns of table \"fcm_token\""
input fcm_token_min_order_by {
  created_at: order_by
  device_id: order_by
  token: order_by
  user_id: order_by
}

"input type for inserting object relation for remote table \"fcm_token\""
input fcm_token_obj_rel_insert_input {
  data: fcm_token_insert_input!
  on_conflict: fcm_token_on_conflict
}

"on conflict condition type for table \"fcm_token\""
input fcm_token_on_conflict {
  constraint: fcm_token_constraint!
  update_columns: [fcm_token_update_column!]!
  where: fcm_token_bool_exp
}

"ordering options when selecting data from \"fcm_token\""
input fcm_token_order_by {
  created_at: order_by
  device_id: order_by
  token: order_by
  user: users_order_by
  user_id: order_by
}

"primary key columns input for table: \"fcm_token\""
input fcm_token_pk_columns_input {
  device_id: String!
}

"input type for updating data in table \"fcm_token\""
input fcm_token_set_input {
  created_at: timestamptz
  device_id: String
  token: String
  user_id: String
}

"Expression to compare the result of casting a column of type geography. Multiple cast targets are combined with logical 'AND'."
input geography_cast_exp {
  geometry: geometry_comparison_exp
}

"expression to compare columns of type geography. All fields are combined with logical 'AND'."
input geography_comparison_exp {
  _cast: geography_cast_exp
  _eq: geography
  _gt: geography
  _gte: geography
  _in: [geography!]
  _is_null: Boolean
  _lt: geography
  _lte: geography
  _neq: geography
  _nin: [geography!]
  "is the column within a distance from a geography value"
  _st_d_within: st_d_within_geography_input
  "does the column spatially intersect the given geography value"
  _st_intersects: geography
}

"Expression to compare the result of casting a column of type geometry. Multiple cast targets are combined with logical 'AND'."
input geometry_cast_exp {
  geography: geography_comparison_exp
}

"expression to compare columns of type geometry. All fields are combined with logical 'AND'."
input geometry_comparison_exp {
  _cast: geometry_cast_exp
  _eq: geometry
  _gt: geometry
  _gte: geometry
  _in: [geometry!]
  _is_null: Boolean
  _lt: geometry
  _lte: geometry
  _neq: geometry
  _nin: [geometry!]
  "does the column contain the given geometry value"
  _st_contains: geometry
  "does the column crosses the given geometry value"
  _st_crosses: geometry
  "is the column within a distance from a geometry value"
  _st_d_within: st_d_within_input
  "is the column equal to given geometry value. Directionality is ignored"
  _st_equals: geometry
  "does the column spatially intersect the given geometry value"
  _st_intersects: geometry
  "does the column 'spatially overlap' (intersect but not completely contain) the given geometry value"
  _st_overlaps: geometry
  "does the column have atleast one point in common with the given geometry value"
  _st_touches: geometry
  "is the column contained in the given geometry value"
  _st_within: geometry
}

"expression to compare columns of type jsonb. All fields are combined with logical 'AND'."
input jsonb_comparison_exp {
  "is the column contained in the given json value"
  _contained_in: jsonb
  "does the column contain the given json value at the top level"
  _contains: jsonb
  _eq: jsonb
  _gt: jsonb
  _gte: jsonb
  "does the string exist as a top-level key in the column"
  _has_key: String
  "do all of these strings exist as top-level keys in the column"
  _has_keys_all: [String!]
  "do any of these strings exist as top-level keys in the column"
  _has_keys_any: [String!]
  _in: [jsonb!]
  _is_null: Boolean
  _lt: jsonb
  _lte: jsonb
  _neq: jsonb
  _nin: [jsonb!]
}

"order by aggregate values of table \"pa_scrape\""
input pa_scrape_aggregate_order_by {
  avg: pa_scrape_avg_order_by
  count: order_by
  max: pa_scrape_max_order_by
  min: pa_scrape_min_order_by
  stddev: pa_scrape_stddev_order_by
  stddev_pop: pa_scrape_stddev_pop_order_by
  stddev_samp: pa_scrape_stddev_samp_order_by
  sum: pa_scrape_sum_order_by
  var_pop: pa_scrape_var_pop_order_by
  var_samp: pa_scrape_var_samp_order_by
  variance: pa_scrape_variance_order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input pa_scrape_append_input {
  contacts: jsonb
  further_information: jsonb
  important_dates: jsonb
  summary: jsonb
}

"input type for inserting array relation for remote table \"pa_scrape\""
input pa_scrape_arr_rel_insert_input {
  data: [pa_scrape_insert_input!]!
  on_conflict: pa_scrape_on_conflict
}

"order by avg() on columns of table \"pa_scrape\""
input pa_scrape_avg_order_by {
  council_id: order_by
  id: order_by
}

"Boolean expression to filter rows from the table \"pa_scrape\". All fields are combined with a logical 'AND'."
input pa_scrape_bool_exp {
  _and: [pa_scrape_bool_exp]
  _not: pa_scrape_bool_exp
  _or: [pa_scrape_bool_exp]
  contacts: jsonb_comparison_exp
  council: council_bool_exp
  council_id: Int_comparison_exp
  further_information: jsonb_comparison_exp
  id: Int_comparison_exp
  important_dates: jsonb_comparison_exp
  list_type: String_comparison_exp
  pa_status: pa_status_bool_exp
  reference: String_comparison_exp
  scraped_at: timestamptz_comparison_exp
  scraper: String_comparison_exp
  summary: jsonb_comparison_exp
  url: String_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input pa_scrape_delete_at_path_input {
  contacts: [String]
  further_information: [String]
  important_dates: [String]
  summary: [String]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input pa_scrape_delete_elem_input {
  contacts: Int
  further_information: Int
  important_dates: Int
  summary: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input pa_scrape_delete_key_input {
  contacts: String
  further_information: String
  important_dates: String
  summary: String
}

"input type for incrementing integer column in table \"pa_scrape\""
input pa_scrape_inc_input {
  council_id: Int
  id: Int
}

"input type for inserting data into table \"pa_scrape\""
input pa_scrape_insert_input {
  contacts: jsonb
  council: council_obj_rel_insert_input
  council_id: Int
  further_information: jsonb
  id: Int
  important_dates: jsonb
  list_type: String
  pa_status: pa_status_obj_rel_insert_input
  reference: String
  scraped_at: timestamptz
  scraper: String
  summary: jsonb
  url: String
}

"order by max() on columns of table \"pa_scrape\""
input pa_scrape_max_order_by {
  council_id: order_by
  id: order_by
  list_type: order_by
  reference: order_by
  scraped_at: order_by
  scraper: order_by
  url: order_by
}

"order by min() on columns of table \"pa_scrape\""
input pa_scrape_min_order_by {
  council_id: order_by
  id: order_by
  list_type: order_by
  reference: order_by
  scraped_at: order_by
  scraper: order_by
  url: order_by
}

"input type for inserting object relation for remote table \"pa_scrape\""
input pa_scrape_obj_rel_insert_input {
  data: pa_scrape_insert_input!
  on_conflict: pa_scrape_on_conflict
}

"on conflict condition type for table \"pa_scrape\""
input pa_scrape_on_conflict {
  constraint: pa_scrape_constraint!
  update_columns: [pa_scrape_update_column!]!
  where: pa_scrape_bool_exp
}

"ordering options when selecting data from \"pa_scrape\""
input pa_scrape_order_by {
  contacts: order_by
  council: council_order_by
  council_id: order_by
  further_information: order_by
  id: order_by
  important_dates: order_by
  list_type: order_by
  pa_status: pa_status_order_by
  reference: order_by
  scraped_at: order_by
  scraper: order_by
  summary: order_by
  url: order_by
}

"primary key columns input for table: \"pa_scrape\""
input pa_scrape_pk_columns_input {
  id: Int!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input pa_scrape_prepend_input {
  contacts: jsonb
  further_information: jsonb
  important_dates: jsonb
  summary: jsonb
}

"input type for updating data in table \"pa_scrape\""
input pa_scrape_set_input {
  contacts: jsonb
  council_id: Int
  further_information: jsonb
  id: Int
  important_dates: jsonb
  list_type: String
  reference: String
  scraped_at: timestamptz
  scraper: String
  summary: jsonb
  url: String
}

"order by stddev() on columns of table \"pa_scrape\""
input pa_scrape_stddev_order_by {
  council_id: order_by
  id: order_by
}

"order by stddev_pop() on columns of table \"pa_scrape\""
input pa_scrape_stddev_pop_order_by {
  council_id: order_by
  id: order_by
}

"order by stddev_samp() on columns of table \"pa_scrape\""
input pa_scrape_stddev_samp_order_by {
  council_id: order_by
  id: order_by
}

"order by sum() on columns of table \"pa_scrape\""
input pa_scrape_sum_order_by {
  council_id: order_by
  id: order_by
}

"order by var_pop() on columns of table \"pa_scrape\""
input pa_scrape_var_pop_order_by {
  council_id: order_by
  id: order_by
}

"order by var_samp() on columns of table \"pa_scrape\""
input pa_scrape_var_samp_order_by {
  council_id: order_by
  id: order_by
}

"order by variance() on columns of table \"pa_scrape\""
input pa_scrape_variance_order_by {
  council_id: order_by
  id: order_by
}

"order by aggregate values of table \"pa_status\""
input pa_status_aggregate_order_by {
  avg: pa_status_avg_order_by
  count: order_by
  max: pa_status_max_order_by
  min: pa_status_min_order_by
  stddev: pa_status_stddev_order_by
  stddev_pop: pa_status_stddev_pop_order_by
  stddev_samp: pa_status_stddev_samp_order_by
  sum: pa_status_sum_order_by
  var_pop: pa_status_var_pop_order_by
  var_samp: pa_status_var_samp_order_by
  variance: pa_status_variance_order_by
}

"input type for inserting array relation for remote table \"pa_status\""
input pa_status_arr_rel_insert_input {
  data: [pa_status_insert_input!]!
  on_conflict: pa_status_on_conflict
}

"order by avg() on columns of table \"pa_status\""
input pa_status_avg_order_by {
  council_id: order_by
}

"Boolean expression to filter rows from the table \"pa_status\". All fields are combined with a logical 'AND'."
input pa_status_bool_exp {
  _and: [pa_status_bool_exp]
  _not: pa_status_bool_exp
  _or: [pa_status_bool_exp]
  address: String_comparison_exp
  application_validated: timestamptz_comparison_exp
  council: council_bool_exp
  council_id: Int_comparison_exp
  council_name: String_comparison_exp
  created_at: timestamptz_comparison_exp
  decision: String_comparison_exp
  decision_issued_date: timestamptz_comparison_exp
  id: String_comparison_exp
  location: geography_comparison_exp
  open: Boolean_comparison_exp
  pa_scrapes: pa_scrape_bool_exp
  proposal: String_comparison_exp
  status: String_comparison_exp
  updated_at: timestamptz_comparison_exp
  url: String_comparison_exp
}

"input type for incrementing integer column in table \"pa_status\""
input pa_status_inc_input {
  council_id: Int
}

"input type for inserting data into table \"pa_status\""
input pa_status_insert_input {
  address: String
  application_validated: timestamptz
  council: council_obj_rel_insert_input
  council_id: Int
  council_name: String
  created_at: timestamptz
  decision: String
  decision_issued_date: timestamptz
  id: String
  location: geography
  open: Boolean
  pa_scrapes: pa_scrape_arr_rel_insert_input
  proposal: String
  status: String
  updated_at: timestamptz
  url: String
}

"order by max() on columns of table \"pa_status\""
input pa_status_max_order_by {
  address: order_by
  application_validated: order_by
  council_id: order_by
  council_name: order_by
  created_at: order_by
  decision: order_by
  decision_issued_date: order_by
  id: order_by
  proposal: order_by
  status: order_by
  updated_at: order_by
  url: order_by
}

"order by min() on columns of table \"pa_status\""
input pa_status_min_order_by {
  address: order_by
  application_validated: order_by
  council_id: order_by
  council_name: order_by
  created_at: order_by
  decision: order_by
  decision_issued_date: order_by
  id: order_by
  proposal: order_by
  status: order_by
  updated_at: order_by
  url: order_by
}

"input type for inserting object relation for remote table \"pa_status\""
input pa_status_obj_rel_insert_input {
  data: pa_status_insert_input!
  on_conflict: pa_status_on_conflict
}

"on conflict condition type for table \"pa_status\""
input pa_status_on_conflict {
  constraint: pa_status_constraint!
  update_columns: [pa_status_update_column!]!
  where: pa_status_bool_exp
}

"ordering options when selecting data from \"pa_status\""
input pa_status_order_by {
  address: order_by
  application_validated: order_by
  council: council_order_by
  council_id: order_by
  council_name: order_by
  created_at: order_by
  decision: order_by
  decision_issued_date: order_by
  id: order_by
  location: order_by
  open: order_by
  pa_scrapes_aggregate: pa_scrape_aggregate_order_by
  proposal: order_by
  status: order_by
  updated_at: order_by
  url: order_by
}

"primary key columns input for table: \"pa_status\""
input pa_status_pk_columns_input {
  id: String!
}

"input type for updating data in table \"pa_status\""
input pa_status_set_input {
  address: String
  application_validated: timestamptz
  council_id: Int
  council_name: String
  created_at: timestamptz
  decision: String
  decision_issued_date: timestamptz
  id: String
  location: geography
  open: Boolean
  proposal: String
  status: String
  updated_at: timestamptz
  url: String
}

"order by stddev() on columns of table \"pa_status\""
input pa_status_stddev_order_by {
  council_id: order_by
}

"order by stddev_pop() on columns of table \"pa_status\""
input pa_status_stddev_pop_order_by {
  council_id: order_by
}

"order by stddev_samp() on columns of table \"pa_status\""
input pa_status_stddev_samp_order_by {
  council_id: order_by
}

"order by sum() on columns of table \"pa_status\""
input pa_status_sum_order_by {
  council_id: order_by
}

"order by var_pop() on columns of table \"pa_status\""
input pa_status_var_pop_order_by {
  council_id: order_by
}

"order by var_samp() on columns of table \"pa_status\""
input pa_status_var_samp_order_by {
  council_id: order_by
}

"order by variance() on columns of table \"pa_status\""
input pa_status_variance_order_by {
  council_id: order_by
}

"order by aggregate values of table \"scrape_log\""
input scrape_log_aggregate_order_by {
  avg: scrape_log_avg_order_by
  count: order_by
  max: scrape_log_max_order_by
  min: scrape_log_min_order_by
  stddev: scrape_log_stddev_order_by
  stddev_pop: scrape_log_stddev_pop_order_by
  stddev_samp: scrape_log_stddev_samp_order_by
  sum: scrape_log_sum_order_by
  var_pop: scrape_log_var_pop_order_by
  var_samp: scrape_log_var_samp_order_by
  variance: scrape_log_variance_order_by
}

"append existing jsonb value of filtered columns with new jsonb value"
input scrape_log_append_input {
  meta: jsonb
}

"input type for inserting array relation for remote table \"scrape_log\""
input scrape_log_arr_rel_insert_input {
  data: [scrape_log_insert_input!]!
  on_conflict: scrape_log_on_conflict
}

"order by avg() on columns of table \"scrape_log\""
input scrape_log_avg_order_by {
  council_id: order_by
  id: order_by
}

"Boolean expression to filter rows from the table \"scrape_log\". All fields are combined with a logical 'AND'."
input scrape_log_bool_exp {
  _and: [scrape_log_bool_exp]
  _not: scrape_log_bool_exp
  _or: [scrape_log_bool_exp]
  council: council_bool_exp
  council_id: Int_comparison_exp
  event: String_comparison_exp
  id: Int_comparison_exp
  meta: jsonb_comparison_exp
  scraper: String_comparison_exp
  ts: timestamptz_comparison_exp
}

"delete the field or element with specified path (for JSON arrays, negative integers count from the end)"
input scrape_log_delete_at_path_input {
  meta: [String]
}

"delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array"
input scrape_log_delete_elem_input {
  meta: Int
}

"delete key/value pair or string element. key/value pairs are matched based on their key value"
input scrape_log_delete_key_input {
  meta: String
}

"input type for incrementing integer column in table \"scrape_log\""
input scrape_log_inc_input {
  council_id: Int
  id: Int
}

"input type for inserting data into table \"scrape_log\""
input scrape_log_insert_input {
  council: council_obj_rel_insert_input
  council_id: Int
  event: String
  id: Int
  meta: jsonb
  scraper: String
  ts: timestamptz
}

"order by max() on columns of table \"scrape_log\""
input scrape_log_max_order_by {
  council_id: order_by
  event: order_by
  id: order_by
  scraper: order_by
  ts: order_by
}

"order by min() on columns of table \"scrape_log\""
input scrape_log_min_order_by {
  council_id: order_by
  event: order_by
  id: order_by
  scraper: order_by
  ts: order_by
}

"input type for inserting object relation for remote table \"scrape_log\""
input scrape_log_obj_rel_insert_input {
  data: scrape_log_insert_input!
  on_conflict: scrape_log_on_conflict
}

"on conflict condition type for table \"scrape_log\""
input scrape_log_on_conflict {
  constraint: scrape_log_constraint!
  update_columns: [scrape_log_update_column!]!
  where: scrape_log_bool_exp
}

"ordering options when selecting data from \"scrape_log\""
input scrape_log_order_by {
  council: council_order_by
  council_id: order_by
  event: order_by
  id: order_by
  meta: order_by
  scraper: order_by
  ts: order_by
}

"primary key columns input for table: \"scrape_log\""
input scrape_log_pk_columns_input {
  id: Int!
}

"prepend existing jsonb value of filtered columns with new jsonb value"
input scrape_log_prepend_input {
  meta: jsonb
}

"input type for updating data in table \"scrape_log\""
input scrape_log_set_input {
  council_id: Int
  event: String
  id: Int
  meta: jsonb
  scraper: String
  ts: timestamptz
}

"order by stddev() on columns of table \"scrape_log\""
input scrape_log_stddev_order_by {
  council_id: order_by
  id: order_by
}

"order by stddev_pop() on columns of table \"scrape_log\""
input scrape_log_stddev_pop_order_by {
  council_id: order_by
  id: order_by
}

"order by stddev_samp() on columns of table \"scrape_log\""
input scrape_log_stddev_samp_order_by {
  council_id: order_by
  id: order_by
}

"order by sum() on columns of table \"scrape_log\""
input scrape_log_sum_order_by {
  council_id: order_by
  id: order_by
}

"order by var_pop() on columns of table \"scrape_log\""
input scrape_log_var_pop_order_by {
  council_id: order_by
  id: order_by
}

"order by var_samp() on columns of table \"scrape_log\""
input scrape_log_var_samp_order_by {
  council_id: order_by
  id: order_by
}

"order by variance() on columns of table \"scrape_log\""
input scrape_log_variance_order_by {
  council_id: order_by
  id: order_by
}

input st_d_within_geography_input {
  distance: Float!
  from: geography!
  use_spheroid: Boolean = true
}

input st_d_within_input {
  distance: Float!
  from: geometry!
}

"expression to compare columns of type timestamptz. All fields are combined with logical 'AND'."
input timestamptz_comparison_exp {
  _eq: timestamptz
  _gt: timestamptz
  _gte: timestamptz
  _in: [timestamptz!]
  _is_null: Boolean
  _lt: timestamptz
  _lte: timestamptz
  _neq: timestamptz
  _nin: [timestamptz!]
}

"order by aggregate values of table \"users\""
input users_aggregate_order_by {
  avg: users_avg_order_by
  count: order_by
  max: users_max_order_by
  min: users_min_order_by
  stddev: users_stddev_order_by
  stddev_pop: users_stddev_pop_order_by
  stddev_samp: users_stddev_samp_order_by
  sum: users_sum_order_by
  var_pop: users_var_pop_order_by
  var_samp: users_var_samp_order_by
  variance: users_variance_order_by
}

"input type for inserting array relation for remote table \"users\""
input users_arr_rel_insert_input {
  data: [users_insert_input!]!
  on_conflict: users_on_conflict
}

"order by avg() on columns of table \"users\""
input users_avg_order_by {
  council_id: order_by
}

"Boolean expression to filter rows from the table \"users\". All fields are combined with a logical 'AND'."
input users_bool_exp {
  _and: [users_bool_exp]
  _not: users_bool_exp
  _or: [users_bool_exp]
  council: council_bool_exp
  council_id: Int_comparison_exp
  created_at: timestamptz_comparison_exp
  email: String_comparison_exp
  fcm_tokens: fcm_token_bool_exp
  id: String_comparison_exp
  location: geography_comparison_exp
  name: String_comparison_exp
}

"input type for incrementing integer column in table \"users\""
input users_inc_input {
  council_id: Int
}

"input type for inserting data into table \"users\""
input users_insert_input {
  council: council_obj_rel_insert_input
  council_id: Int
  created_at: timestamptz
  email: String
  fcm_tokens: fcm_token_arr_rel_insert_input
  id: String
  location: geography
  name: String
}

"order by max() on columns of table \"users\""
input users_max_order_by {
  council_id: order_by
  created_at: order_by
  email: order_by
  id: order_by
  name: order_by
}

"order by min() on columns of table \"users\""
input users_min_order_by {
  council_id: order_by
  created_at: order_by
  email: order_by
  id: order_by
  name: order_by
}

"input type for inserting object relation for remote table \"users\""
input users_obj_rel_insert_input {
  data: users_insert_input!
  on_conflict: users_on_conflict
}

"on conflict condition type for table \"users\""
input users_on_conflict {
  constraint: users_constraint!
  update_columns: [users_update_column!]!
  where: users_bool_exp
}

"ordering options when selecting data from \"users\""
input users_order_by {
  council: council_order_by
  council_id: order_by
  created_at: order_by
  email: order_by
  fcm_tokens_aggregate: fcm_token_aggregate_order_by
  id: order_by
  location: order_by
  name: order_by
}

"primary key columns input for table: \"users\""
input users_pk_columns_input {
  id: String!
}

"input type for updating data in table \"users\""
input users_set_input {
  council_id: Int
  created_at: timestamptz
  email: String
  id: String
  location: geography
  name: String
}

"order by stddev() on columns of table \"users\""
input users_stddev_order_by {
  council_id: order_by
}

"order by stddev_pop() on columns of table \"users\""
input users_stddev_pop_order_by {
  council_id: order_by
}

"order by stddev_samp() on columns of table \"users\""
input users_stddev_samp_order_by {
  council_id: order_by
}

"order by sum() on columns of table \"users\""
input users_sum_order_by {
  council_id: order_by
}

"order by var_pop() on columns of table \"users\""
input users_var_pop_order_by {
  council_id: order_by
}

"order by var_samp() on columns of table \"users\""
input users_var_samp_order_by {
  council_id: order_by
}

"order by variance() on columns of table \"users\""
input users_variance_order_by {
  council_id: order_by
}


scalar geography

scalar geometry

scalar jsonb

scalar timestamptz
